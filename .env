# Choose a provider:
# openai | openai_compat | anthropic | gemini | ollama | hf_local

# OpenAI
# MODEL_PROVIDER=openai
# MODEL=gpt-4o-mini
# OPENAI_API_KEY=KEY-HERE

# OpenAI-compatible (proxy) â€” same schema, custom base URL
# MODEL_PROVIDER=openai_compat
# OPENAI_COMPAT_BASE_URL=http://localhost:1234/v1
# OPENAI_COMPAT_API_KEY=not-needed-or-your-key

# Anthropic (Claude)
# MODEL_PROVIDER=anthropic
# MODEL=claude-3-5-sonnet-20240620
# ANTHROPIC_API_KEY=KEY-HERE

# Google (Gemini)
# MODEL_PROVIDER=gemini
# MODEL=gemini-1.5-pro
# GOOGLE_API_KEY=KEY-HERE

# Gemini-specific rate limit handling
# GEMINI_MAX_RETRIES=5
# GEMINI_BACKOFF_MIN=2.0
# GEMINI_BACKOFF_MAX=30.0
# GEMINI_SLEEP=1.0  # seconds between successful Gemini calls

# Ollama (local)
# MODEL_PROVIDER=ollama
# MODEL=llama3
# OLLAMA_BASE_URL=http://localhost:11434

# Hugging Face local (Transformers)
# MODEL_PROVIDER=hf_local
# MODEL=HuggingFaceH4/zephyr-7b-beta

PROMPTS="crescendo_prompts.json"
TEMP="0.7"
MAX_TOKENS="400"
START="5000"
COUNT="5"
SEED="1337"
OUTDIR="runs"
BRANCHING="1"
MEM_TURN="2"
MAX_BRANCH="2"
RANDOMIZE="1"
JUDGE_DEBUG="1"
HB_RATIO=3:1

# Optional global throttle (applies to all providers)
# SLEEP_AFTER_REPLY=0.0
